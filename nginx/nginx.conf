# KaiTech API Gateway - Nginx Configuration
# Advanced API gateway with load balancing, SSL, caching, and monitoring

# Global settings
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

# Events block
events {
    worker_connections 2048;
    use epoll;
    multi_accept on;
}

# HTTP block
http {
    # Basic settings
    include /etc/nginx/mime.types;
    default_type application/octet-stream;
    
    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    '$request_time $upstream_response_time';
    
    log_format api '$remote_addr - $remote_user [$time_local] "$request" '
                   '$status $body_bytes_sent "$http_referer" '
                   '"$http_user_agent" "$http_x_forwarded_for" '
                   '$request_time $upstream_response_time '
                   'upstream="$upstream_addr" service="$proxy_upstream_name"';
    
    access_log /var/log/nginx/access.log main;
    
    # Performance optimization
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 10M;
    
    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_comp_level 6;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;
    
    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header Referrer-Policy "no-referrer-when-downgrade" always;
    add_header X-Powered-By "KaiTech-Gateway/2.0" always;
    
    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=news_limit:10m rate=20r/s;
    limit_req_zone $binary_remote_addr zone=ai_limit:10m rate=5r/s;
    
    # Connection limiting  
    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;
    
    # Upstream definitions
    upstream news_service {
        least_conn;
        server news-service:3000 max_fails=3 fail_timeout=30s;
        server news-service-2:3000 max_fails=3 fail_timeout=30s backup;
        keepalive 32;
    }
    
    upstream ai_service {
        least_conn;
        server ai-service:3001 max_fails=3 fail_timeout=30s;
        server ai-service-2:3001 max_fails=3 fail_timeout=30s backup;
        keepalive 32;
    }
    
    upstream frontend_service {
        least_conn;
        server web:8080 max_fails=3 fail_timeout=30s;
        keepalive 16;
    }
    
    # Redis upstream for caching
    upstream redis_backend {
        server redis:6379 max_fails=2 fail_timeout=10s;
    }
    
    # Cache configuration
    proxy_cache_path /var/cache/nginx/api levels=1:2 keys_zone=api_cache:100m max_size=1g 
                     inactive=60m use_temp_path=off;
    
    # Map for API versioning
    map $http_accept $api_version {
        default "v1";
        "~*application/vnd\.kaitech\.v2" "v2";
        "~*application/vnd\.kaitech\.v1" "v1";
    }
    
    # Map for service routing
    map $request_uri $service_name {
        ~^/api/news.*     "news";
        ~^/api/ai.*       "ai";
        default           "frontend";
    }
    
    # Health check configuration
    upstream_conf {
        server news-service:3000;
        server ai-service:3001;
    }
    
    # HTTPS redirect server (port 80)
    server {
        listen 80;
        server_name _;
        return 301 https://$host$request_uri;
    }
    
    # Main HTTPS server
    server {
        listen 443 ssl http2;
        server_name localhost kai-tech.local _;
        
        # SSL configuration
        ssl_certificate /etc/nginx/ssl/kaitech-local.crt;
        ssl_certificate_key /etc/nginx/ssl/kaitech-local.key;
        
        # Modern SSL configuration
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;
        
        # HSTS
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        
        # API Gateway specific headers
        add_header X-Gateway-Version "2.0" always;
        add_header X-Request-ID $request_id always;
        
        # Global rate limiting
        limit_req zone=api_limit burst=20 nodelay;
        limit_conn conn_limit 50;
        
        # Root location - serve frontend
        location / {
            proxy_pass http://frontend_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header X-Request-ID $request_id;
            
            # Caching for static assets
            location ~* \.(css|js|png|jpg|jpeg|gif|svg|ico|woff|woff2)$ {
                proxy_pass http://frontend_service;
                proxy_cache api_cache;
                proxy_cache_valid 200 1h;
                proxy_cache_valid 404 1m;
                add_header X-Cache-Status $upstream_cache_status always;
                expires 1h;
            }
        }
        
        # API Gateway routes
        
        # Health check endpoint
        location /health {
            access_log /var/log/nginx/health.log api;
            
            content_by_lua_block {
                local http = require "resty.http"
                local cjson = require "cjson"
                
                local services = {
                    {name = "news", url = "http://news-service:3000/health"},
                    {name = "ai", url = "http://ai-service:3001/health"}
                }
                
                local results = {}
                local overall_status = "healthy"
                
                for _, service in ipairs(services) do
                    local httpc = http.new()
                    local res, err = httpc:request_uri(service.url, {
                        timeout = 5000,
                        keepalive_timeout = 60000,
                        keepalive_pool = 10
                    })
                    
                    if res and res.status == 200 then
                        results[service.name] = "healthy"
                    else
                        results[service.name] = "unhealthy"
                        overall_status = "degraded"
                    end
                end
                
                local response = {
                    status = overall_status,
                    timestamp = ngx.time(),
                    gateway_version = "2.0",
                    services = results,
                    request_id = ngx.var.request_id
                }
                
                ngx.header["Content-Type"] = "application/json"
                ngx.header["X-Health-Check"] = "true"
                
                if overall_status ~= "healthy" then
                    ngx.status = 503
                end
                
                ngx.say(cjson.encode(response))
            }
        }
        
        # News API routes
        location /api/news {
            access_log /var/log/nginx/api_news.log api;
            limit_req zone=news_limit burst=30 nodelay;
            
            # Add API-specific headers
            proxy_set_header X-Service-Name "news";
            proxy_set_header X-API-Version $api_version;
            proxy_set_header X-Request-ID $request_id;
            
            # Enhanced proxy settings
            proxy_pass http://news_service;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeouts
            proxy_connect_timeout 5s;
            proxy_send_timeout 10s;
            proxy_read_timeout 10s;
            
            # Caching for news data
            proxy_cache api_cache;
            proxy_cache_key "$scheme$request_method$host$request_uri";
            proxy_cache_valid 200 5m;
            proxy_cache_valid 404 1m;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;
            proxy_cache_lock on;
            
            add_header X-Cache-Status $upstream_cache_status always;
            add_header X-Service-Response-Time $upstream_response_time always;
            
            # Error handling
            error_page 500 502 503 504 = @news_error;
        }
        
        # AI API routes  
        location /api/ai {
            access_log /var/log/nginx/api_ai.log api;
            limit_req zone=ai_limit burst=10 nodelay;
            
            # Add API-specific headers
            proxy_set_header X-Service-Name "ai";
            proxy_set_header X-API-Version $api_version;
            proxy_set_header X-Request-ID $request_id;
            
            # Enhanced proxy settings for AI service
            proxy_pass http://ai_service;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Longer timeouts for AI processing
            proxy_connect_timeout 10s;
            proxy_send_timeout 30s;
            proxy_read_timeout 60s;
            
            # Disable caching for most AI endpoints (except specific ones)
            proxy_cache off;
            
            # Cache sentiment analysis and classification results
            location ~* /api/ai/(sentiment|classify|keywords)$ {
                proxy_pass http://ai_service;
                proxy_cache api_cache;
                proxy_cache_key "$scheme$request_method$host$request_uri$request_body";
                proxy_cache_valid 200 1h;
                proxy_cache_methods POST;
                add_header X-Cache-Status $upstream_cache_status always;
            }
            
            add_header X-Service-Response-Time $upstream_response_time always;
            
            # Error handling
            error_page 500 502 503 504 = @ai_error;
        }
        
        # WebSocket support for real-time features
        location /ws {
            proxy_pass http://frontend_service;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocket timeouts
            proxy_connect_timeout 7d;
            proxy_send_timeout 7d;
            proxy_read_timeout 7d;
        }
        
        # API documentation
        location /docs {
            proxy_pass http://frontend_service/docs;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }
        
        # Metrics endpoint for monitoring
        location /metrics {
            access_log off;
            allow 10.0.0.0/8;
            allow 172.16.0.0/12;
            allow 192.168.0.0/16;
            allow 127.0.0.1;
            deny all;
            
            content_by_lua_block {
                local cjson = require "cjson"
                
                -- Gather nginx metrics
                local metrics = {
                    nginx_version = ngx.var.nginx_version,
                    connections_active = ngx.var.connections_active,
                    connections_reading = ngx.var.connections_reading,
                    connections_writing = ngx.var.connections_writing,
                    connections_waiting = ngx.var.connections_waiting,
                    timestamp = ngx.time(),
                    uptime = ngx.time() - ngx.start_time
                }
                
                ngx.header["Content-Type"] = "application/json"
                ngx.say(cjson.encode(metrics))
            }
        }
        
        # Error pages
        error_page 404 = @not_found;
        error_page 500 502 503 504 = @server_error;
        
        # Custom error handlers
        location @news_error {
            internal;
            add_header Content-Type application/json always;
            return 503 '{"error": "News service temporarily unavailable", "code": "SERVICE_UNAVAILABLE", "request_id": "$request_id", "timestamp": "$time_iso8601"}';
        }
        
        location @ai_error {
            internal;
            add_header Content-Type application/json always;
            return 503 '{"error": "AI service temporarily unavailable", "code": "SERVICE_UNAVAILABLE", "request_id": "$request_id", "timestamp": "$time_iso8601"}';
        }
        
        location @not_found {
            internal;
            add_header Content-Type application/json always;
            return 404 '{"error": "Endpoint not found", "code": "NOT_FOUND", "request_id": "$request_id", "timestamp": "$time_iso8601"}';
        }
        
        location @server_error {
            internal;
            add_header Content-Type application/json always;
            return 500 '{"error": "Internal server error", "code": "INTERNAL_ERROR", "request_id": "$request_id", "timestamp": "$time_iso8601"}';
        }
        
        # Security - block common attacks
        location ~ /\. {
            deny all;
            access_log off;
            log_not_found off;
        }
        
        location ~* \.(env|git|svn|htaccess|htpasswd)$ {
            deny all;
            access_log off;
            log_not_found off;
        }
        
        # Block malicious requests
        if ($request_method !~ ^(GET|HEAD|POST|PUT|DELETE|OPTIONS)$) {
            return 405;
        }
        
        if ($http_user_agent ~* (wget|curl|libwww|python|nikto|scan|nmap|sqlmap)) {
            return 403;
        }
    }
    
    # Monitoring and admin server (internal only)
    server {
        listen 8080;
        server_name localhost;
        
        # Restrict access
        allow 127.0.0.1;
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
        
        # Nginx status
        location /nginx_status {
            stub_status on;
            access_log off;
        }
        
        # Upstream status
        location /upstream_status {
            upstream_show;
        }
        
        # Configuration check
        location /config_check {
            content_by_lua_block {
                ngx.say("Nginx configuration is valid")
                ngx.say("Server time: " .. os.date())
                ngx.say("Gateway version: 2.0")
            }
        }
    }
}

# Stream block for TCP/UDP load balancing (if needed)
stream {
    # Log format for stream
    log_format basic '$remote_addr [$time_local] '
                     '$protocol $status $bytes_sent $bytes_received '
                     '$session_time';
    
    access_log /var/log/nginx/stream.log basic;
    
    # Example: Load balance Redis connections
    upstream redis_stream {
        server redis:6379;
    }
    
    # Redis proxy (if external access needed)
    server {
        listen 6380;
        proxy_pass redis_stream;
        proxy_timeout 3s;
        proxy_responses 1;
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
    }
}